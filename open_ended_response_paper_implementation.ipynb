{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "X5RKYpObgq3Y"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import ast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PhvPOr6EhiZu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "c_uTmwHnpNj0",
        "outputId": "080529f3-53e4-4dfa-e042-688036ba0c6c"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "*some markdown* test"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Markdown\n",
        "display(Markdown('*some markdown* test'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkeW-KKj239P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VfsIj-WS0AvI"
      },
      "outputs": [],
      "source": [
        "# @title google api key\n",
        "# os.environ['GOOGLE_API_KEY'] = <api key>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "siJ2SP8jjP4f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/sudesh/git/Automated interview/.py3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from google import generativeai as genai\n",
        "genai.configure()\n",
        "\n",
        "model = genai.GenerativeModel('gemini-pro')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "**Mechanical Lemonade**\n",
              "\n",
              "In a realm of gears and steam,\n",
              "Where innovation's dreams gleam,\n",
              "A marvel arose, a wondrous sight,\n",
              "Mechanical Lemonade, a pure delight.\n",
              "\n",
              "Its pistons churned, a rhythmic beat,\n",
              "As lemons danced, their essence sweet,\n",
              "Through tubes and valves, a liquid gold,\n",
              "A thirst-quenching elixir, a story to be told.\n",
              "\n",
              "With every sip, a burst of zest,\n",
              "A symphony of flavors, truly blessed,\n",
              "Its tangy sweetness, a refreshing treat,\n",
              "A taste of summer, a moment complete.\n",
              "\n",
              "Its gears and cogs, a mesmerizing dance,\n",
              "A testament to human brilliance,\n",
              "A machine that brought joy to all,\n",
              "Mechanical Lemonade, standing tall.\n",
              "\n",
              "In bustling streets and crowded fairs,\n",
              "It quenched the thirst, banished all cares,\n",
              "A symbol of progress, a marvel to behold,\n",
              "Mechanical Lemonade, a story to be told.\n",
              "\n",
              "So raise a glass to this wondrous creation,\n",
              "A testament to innovation's liberation,\n",
              "Mechanical Lemonade, a timeless delight,\n",
              "A taste of summer, a pure and bright."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# we need temprature as 1 to get consistent results\n",
        "temp_0_config = genai.GenerationConfig( **{  \n",
        "    # \"candidate_count\": int | None = None\n",
        "    # \"stop_sequences\": Iterable[str] | None = None\n",
        "    # \"max_output_tokens\": int | None = None\n",
        "    \"temperature\": 0\n",
        "    # \"top_p\": float | None = None\n",
        "    # \"top_k\": int | None = None\n",
        "    })\n",
        "# model_response = model.generate_content(\"write a poem about machnical lemonade\",generation_config=temp_0_config).text\n",
        "# display(Markdown(model_response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "r2Zsmgi8vh5B"
      },
      "outputs": [],
      "source": [
        "def judge_answer(q,a,c):\n",
        "  response = model.generate_content(f\"\"\"\n",
        "you are a teaching assistent ai who will help students correct their answers.\n",
        "\n",
        "for a given question, criteria and student answer tell the student what they did correct and where they have to improve their understanding of the subject.\n",
        "\n",
        "input:\n",
        "```\n",
        "question: {q}\n",
        "criteria: {c}\n",
        "student answer: {a}\n",
        "\n",
        "output format\n",
        "```\n",
        "Correct points:\n",
        "1.\n",
        "2.\n",
        "...\n",
        "Points to improve:\n",
        "1.\n",
        "2.\n",
        "...\n",
        "\n",
        "summery:\n",
        "Overall,...\n",
        "```\n",
        "\n",
        "end your summary with words of Encouragement like good job! or keep up the effort etc.\n",
        "do not repeate the inputs in your response\n",
        "\n",
        "\"\"\",generation_config=temp_0_config)\n",
        "  return response.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzLbnIcOufOr"
      },
      "source": [
        "\n",
        "FreeText can use question content to automatically establish grading criteria, or it can use the assessment criteria to improve the text of the question.\n",
        "The latter process works by asking the AI to serve as\n",
        "a student and answer a question while oblivious to the\n",
        "instructor’s grading criteria. Then, the answer is automatically evaluated by a separate instantiation of the\n",
        "LLM — this time, against the instructor criteria. The\n",
        "assessment model determines if the student has been\n",
        "unfairly penalized due to omission of requirements (or\n",
        "a lack of clarity) in the original question text. If so, the\n",
        "question is updated to better encompass the requirements of the grading criteria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "WZK5jQzduqCz",
        "outputId": "090e4b6e-bbbb-4c0e-b3fb-8f0d040edb48"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "student is being unfairly judged.\n",
              "\n",
              "reason:\n",
              "The original question does not mention anything about the Ptolemaic dynasty or why they created the Rosetta Stone. Therefore, the student cannot be penalized for not including this information in their answer."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"alternative questions\": [\n",
            "    \"Explain the purpose of the Rosetta Stone and its significance in understanding the Ptolemaic dynasty.\",\n",
            "    \"Describe the historical context surrounding the creation of the Rosetta Stone, including the role of the Ptolemaic dynasty.\",\n",
            "    \"Discuss the reasons why the Ptolemaic dynasty commissioned the creation of the Rosetta Stone and its impact on our understanding of ancient Egypt.\"\n",
            "  ]\n",
            "}\n",
            "{'alternative questions': ['Explain the purpose of the Rosetta Stone and its significance in understanding the Ptolemaic dynasty.', 'Describe the historical context surrounding the creation of the Rosetta Stone, including the role of the Ptolemaic dynasty.', 'Discuss the reasons why the Ptolemaic dynasty commissioned the creation of the Rosetta Stone and its impact on our understanding of ancient Egypt.']}\n"
          ]
        }
      ],
      "source": [
        "# @title Question evaluation\n",
        "question = \"What is the Rosetta Stone?\" # @param {type:\"string\"}\n",
        "criteria = \"Mention why the Ptolemaic dynasty created the Rosetta Stone\" # @param {type:\"string\"}\n",
        "\n",
        "def refine_question_wrt_criteria(question,criteria):\n",
        "  response = model.generate_content(f\"\"\"\n",
        "  You are a model student with best grades.\n",
        "  Answer the following question. try to be consise and presise.\n",
        "  question:{question}\n",
        "\n",
        "  do not repeate the input in your response\n",
        "  \"\"\"\n",
        "  ,generation_config=temp_0_config)\n",
        "  # display(Markdown(response.text))\n",
        "  model_answer = response.text\n",
        "  judjement = judge_answer(question,model_answer,criteria)\n",
        "  # display(Markdown(judjement))\n",
        "\n",
        "\n",
        "  #  The assessment model determines if the student has been unfairly penalized due to omission of requirements (or a lack of clarity) in the original question text\n",
        "\n",
        "  response = model.generate_content(f'''\n",
        "  You are a AI teaching assistent.\n",
        "  for a given question, answer, evaluation criteria and evaluation.\n",
        "  determine if the student has been unfairly penalized due to omission of requirements (or a lack of clarity) in the original question text.\n",
        "\n",
        "  question: {question}\n",
        "  criteria: {criteria}\n",
        "  answer: {model_answer}\n",
        "  evaluation: {judjement}\n",
        "\n",
        "  output format\n",
        "  ```\n",
        "  student is being fairly/unfairly judged.\n",
        "\n",
        "  reason:\n",
        "  ```\n",
        "  You need to strictly follow the output format.\n",
        "  '''\n",
        "  ,generation_config=temp_0_config)\n",
        "  display(Markdown(response.text))\n",
        "  # is_fair = re.search(r\"your question is (fair|unfair)\\.\",response.text)\n",
        "  is_fair = re.search(r\"student is being (fairly|unfairly) judged\\.\",response.text)\n",
        "  if is_fair is not None and is_fair[1].lower() == \"unfairly\":\n",
        "      response = model.generate_content(f'''\n",
        "      you are a teaching assistent AI.\n",
        "      a question is evaluated based on the grading criteria.\n",
        "      students are getting unfairly penalized due to omission of requirements (or a lack of clarity) in the original question text.\n",
        "      given the question and grading criteria, suggest a list of alternative questions such that they better encompass the requirements of the grading criteria.\n",
        "\n",
        "      strictly do not explicitly add grading criteria into the question.\n",
        "\n",
        "      question: {question}\n",
        "      grading criteria: {criteria}\n",
        "\n",
        "      output json format\n",
        "      {{\"alternative questions\": [\"question 1\",\"question 2\",...]}}\n",
        "      ''',generation_config=temp_0_config)\n",
        "      # display(Markdown(response.text))\n",
        "      print(response.text)\n",
        "\n",
        "      return ast.literal_eval(response.text)\n",
        "  else:\n",
        "      return {\n",
        "        \"alternative questions\": []\n",
        "      }\n",
        "\n",
        "print(refine_question_wrt_criteria(question,criteria))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "crl1n8vZj5y-",
        "outputId": "6e0782df-e9f0-4f30-ada9-a786e04ef3d9"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "**Correct points:**\n",
              "\n",
              "1. You correctly described the double helix structure of DNA.\n",
              "2. You correctly named the nitrogenous bases (ATGC) that form the rungs of the DNA ladder.\n",
              "\n",
              "**Points to improve:**\n",
              "\n",
              "1. You stated that the scaffold of DNA is made of sugars and phosphates. While this is partially correct, you should also mention that the scaffold consists of alternating units of deoxyribose sugar and phosphate groups.\n",
              "2. You mentioned that the base pairs bind using hydrogen bonds, but you did not specify the specific pairing rules. You should state that adenine (A) always pairs with thymine (T), and cytosine (C) always pairs with guanine (G).\n",
              "\n",
              "**Summary:**\n",
              "\n",
              "Overall, your answer demonstrates a basic understanding of the structure of DNA. However, you should revise the details on the composition of the scaffold and the specific base pairing rules. Keep up the effort!"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title Student answer evaluation\n",
        "question = \"What are the components and structure of a molecule of DNA?\" # @param {type:\"string\"}\n",
        "criteria = \"\" # @param {type:\"string\"}\n",
        "student_answer = \"DNA is a complex molecule and it is shaped like a double helix ladder, where the rungs are base pairs ATGC and the scaffold is sugars and phosphates. The base pairs bind (A with G) and (C with T) using hydrogen bonds, which can be separated when the DNA is being read or duplicated\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "display(Markdown(judge_answer(question,student_answer,criteria)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmL3N1BBmTe9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
